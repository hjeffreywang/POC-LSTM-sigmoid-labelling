{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a442627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dtale as dt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70b3e784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeffwa/anaconda3/envs/DL_new/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning:\n",
      "\n",
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1519127e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17dc07b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=pd.read_pickle('y_train.pkl')\n",
    "y_test=pd.read_pickle('y_test.pkl')\n",
    "x_test=pd.read_pickle('x_test.pkl')\n",
    "x_train=pd.read_pickle('x_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a5b9056",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_col='log_bullish_week'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebce1d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y=y_test[pred_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d49b1017",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data1=x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59562ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=y_train[pred_col]\n",
    "#Y_train=df['Close']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfd00fd",
   "metadata": {},
   "source": [
    "# Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00626e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import joblib\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        #normalize\n",
    "\n",
    "    \n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        new_shape = (len(Y), 1)\n",
    "        self.Y = torch.tensor(Y, dtype=torch.float32)\n",
    "        self.Y = self.Y.view(new_shape)\n",
    "        \n",
    "    \n",
    "        \n",
    "        #self.Y = self.Y.view(new_shape)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86026c55",
   "metadata": {},
   "source": [
    "# Normalize the X data\n",
    "scaler = StandardScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2fd11d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sc.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler = StandardScaler()\n",
    "scaled_fit=scaler.fit_transform(training_data1)\n",
    "        \n",
    "\n",
    "joblib.dump(scaler, 'sc.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "958bf532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler_y = StandardScaler()\n",
    "scaled_fit_y=Y_train.values.reshape(-1, 1)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0e6bc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X is a DataFrame with 5 columns and Y is a DataFrame with 1 column\n",
    "#train_data = MyDataset(scaled_fit, Y_train.values.reshape(-1, 1))\n",
    "train_data = MyDataset(scaled_fit, scaled_fit_y)\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=32) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f86ff356",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Heiken Ashi Low</th>\n",
       "      <th>Heiken Ashi Close</th>\n",
       "      <th>log_normalized_change</th>\n",
       "      <th>log_price_range</th>\n",
       "      <th>log_premarket_changes</th>\n",
       "      <th>log_Smart_Money</th>\n",
       "      <th>log_volume_deviation</th>\n",
       "      <th>log_norm_avg_deviation_200</th>\n",
       "      <th>log_norm_avg_deviation_300</th>\n",
       "      <th>log_ha_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>110.269111</td>\n",
       "      <td>110.852270</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.002583</td>\n",
       "      <td>-0.000265</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>-0.441282</td>\n",
       "      <td>0.091401</td>\n",
       "      <td>0.120446</td>\n",
       "      <td>0.001375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>110.242772</td>\n",
       "      <td>110.584226</td>\n",
       "      <td>-0.001326</td>\n",
       "      <td>0.005248</td>\n",
       "      <td>-0.002454</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>-0.196779</td>\n",
       "      <td>0.089073</td>\n",
       "      <td>0.118519</td>\n",
       "      <td>-0.002421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>110.419053</td>\n",
       "      <td>111.063419</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.016162</td>\n",
       "      <td>-0.000729</td>\n",
       "      <td>0.003446</td>\n",
       "      <td>0.040220</td>\n",
       "      <td>0.090741</td>\n",
       "      <td>0.120595</td>\n",
       "      <td>0.004324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>109.611300</td>\n",
       "      <td>110.257496</td>\n",
       "      <td>-0.010508</td>\n",
       "      <td>0.011656</td>\n",
       "      <td>-0.002849</td>\n",
       "      <td>-0.007659</td>\n",
       "      <td>0.427762</td>\n",
       "      <td>0.079324</td>\n",
       "      <td>0.109514</td>\n",
       "      <td>-0.007283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>109.941750</td>\n",
       "      <td>110.378666</td>\n",
       "      <td>0.008521</td>\n",
       "      <td>0.008049</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.007385</td>\n",
       "      <td>0.098847</td>\n",
       "      <td>0.086907</td>\n",
       "      <td>0.117429</td>\n",
       "      <td>0.001098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4262</th>\n",
       "      <td>402.350006</td>\n",
       "      <td>408.007500</td>\n",
       "      <td>0.010572</td>\n",
       "      <td>0.027746</td>\n",
       "      <td>-0.003129</td>\n",
       "      <td>0.013701</td>\n",
       "      <td>0.231950</td>\n",
       "      <td>0.047874</td>\n",
       "      <td>0.004319</td>\n",
       "      <td>0.010545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4263</th>\n",
       "      <td>405.563838</td>\n",
       "      <td>415.707497</td>\n",
       "      <td>0.014452</td>\n",
       "      <td>0.013066</td>\n",
       "      <td>0.009835</td>\n",
       "      <td>0.004617</td>\n",
       "      <td>0.223718</td>\n",
       "      <td>0.062525</td>\n",
       "      <td>0.019111</td>\n",
       "      <td>0.018696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4264</th>\n",
       "      <td>410.635667</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>-0.010686</td>\n",
       "      <td>0.014202</td>\n",
       "      <td>-0.012531</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.125602</td>\n",
       "      <td>0.052183</td>\n",
       "      <td>0.008807</td>\n",
       "      <td>-0.006534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4265</th>\n",
       "      <td>408.100006</td>\n",
       "      <td>409.752502</td>\n",
       "      <td>-0.006130</td>\n",
       "      <td>0.007786</td>\n",
       "      <td>-0.006228</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>-0.323262</td>\n",
       "      <td>0.046425</td>\n",
       "      <td>0.003089</td>\n",
       "      <td>-0.007894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4266</th>\n",
       "      <td>407.570007</td>\n",
       "      <td>412.029999</td>\n",
       "      <td>0.012994</td>\n",
       "      <td>0.021650</td>\n",
       "      <td>-0.002345</td>\n",
       "      <td>0.015339</td>\n",
       "      <td>0.095679</td>\n",
       "      <td>0.059639</td>\n",
       "      <td>0.016367</td>\n",
       "      <td>0.005543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3968 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Heiken Ashi Low  Heiken Ashi Close  log_normalized_change  \\\n",
       "299        110.269111         110.852270               0.000199   \n",
       "300        110.242772         110.584226              -0.001326   \n",
       "301        110.419053         111.063419               0.002717   \n",
       "302        109.611300         110.257496              -0.010508   \n",
       "303        109.941750         110.378666               0.008521   \n",
       "...               ...                ...                    ...   \n",
       "4262       402.350006         408.007500               0.010572   \n",
       "4263       405.563838         415.707497               0.014452   \n",
       "4264       410.635667         413.000000              -0.010686   \n",
       "4265       408.100006         409.752502              -0.006130   \n",
       "4266       407.570007         412.029999               0.012994   \n",
       "\n",
       "      log_price_range  log_premarket_changes  log_Smart_Money  \\\n",
       "299          0.002583              -0.000265         0.000464   \n",
       "300          0.005248              -0.002454         0.001128   \n",
       "301          0.016162              -0.000729         0.003446   \n",
       "302          0.011656              -0.002849        -0.007659   \n",
       "303          0.008049               0.001136         0.007385   \n",
       "...               ...                    ...              ...   \n",
       "4262         0.027746              -0.003129         0.013701   \n",
       "4263         0.013066               0.009835         0.004617   \n",
       "4264         0.014202              -0.012531         0.001845   \n",
       "4265         0.007786              -0.006228         0.000098   \n",
       "4266         0.021650              -0.002345         0.015339   \n",
       "\n",
       "      log_volume_deviation  log_norm_avg_deviation_200  \\\n",
       "299              -0.441282                    0.091401   \n",
       "300              -0.196779                    0.089073   \n",
       "301               0.040220                    0.090741   \n",
       "302               0.427762                    0.079324   \n",
       "303               0.098847                    0.086907   \n",
       "...                    ...                         ...   \n",
       "4262              0.231950                    0.047874   \n",
       "4263              0.223718                    0.062525   \n",
       "4264              0.125602                    0.052183   \n",
       "4265             -0.323262                    0.046425   \n",
       "4266              0.095679                    0.059639   \n",
       "\n",
       "      log_norm_avg_deviation_300  log_ha_change  \n",
       "299                     0.120446       0.001375  \n",
       "300                     0.118519      -0.002421  \n",
       "301                     0.120595       0.004324  \n",
       "302                     0.109514      -0.007283  \n",
       "303                     0.117429       0.001098  \n",
       "...                          ...            ...  \n",
       "4262                    0.004319       0.010545  \n",
       "4263                    0.019111       0.018696  \n",
       "4264                    0.008807      -0.006534  \n",
       "4265                    0.003089      -0.007894  \n",
       "4266                    0.016367       0.005543  \n",
       "\n",
       "[3968 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84769f2f",
   "metadata": {},
   "source": [
    "# Pytorch setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30f5fc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your LSTM model\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, dropout):\n",
    "        super(LSTM,self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Reshape the input tensor to match the expected shape of (batch_size, sequence_length, input_size)\n",
    "        x = x.view(-1, 1, x.shape[-1])\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        output, (h_n, c_n) = self.lstm(x)\n",
    "        # Apply activation function\n",
    "        output = self.relu(output)\n",
    "        output = self.dropout(output[:, -1, :])\n",
    "        \n",
    "        output = self.fc(output)\n",
    "        output = self.sigmoid(output)\n",
    "\n",
    "        return torch.squeeze(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc58cf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50200\n",
    "learning_rate = 0.0005\n",
    "num_layers=5\n",
    "input_size = 10\n",
    "hidden_size = 90\n",
    "output_size = 1\n",
    "dropout=.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5510f4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db282c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = LSTM(input_size=input_size, hidden_size=hidden_size,num_layers=num_layers,output_size=1,dropout=dropout)#output_size=1\n",
    "\n",
    "model.to(device)\n",
    "train_data_x=train_data.X.to(device)\n",
    "train_data_y=train_data.Y.to(device)\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003,weight_decay=6e-7) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fe37727",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 0.72633\n",
      "Epoch: 100, loss: 0.37494\n",
      "Epoch: 200, loss: 0.34791\n",
      "Epoch: 300, loss: 0.30058\n",
      "Epoch: 400, loss: 0.25165\n",
      "Epoch: 500, loss: 0.22959\n",
      "Epoch: 600, loss: 0.20974\n",
      "Epoch: 700, loss: 0.18964\n",
      "Epoch: 800, loss: 0.19281\n",
      "Epoch: 900, loss: 0.29543\n",
      "Epoch: 1000, loss: 0.20863\n",
      "Epoch: 1100, loss: 0.17710\n",
      "Epoch: 1200, loss: 0.17765\n",
      "Epoch: 1300, loss: 0.23975\n",
      "Epoch: 1400, loss: 0.20177\n",
      "Epoch: 1500, loss: 0.11599\n",
      "Epoch: 1600, loss: 0.12145\n",
      "Epoch: 1700, loss: 0.20327\n",
      "Epoch: 1800, loss: 0.12347\n",
      "Epoch: 1900, loss: 0.10357\n",
      "Epoch: 2000, loss: 0.07243\n",
      "Epoch: 2100, loss: 0.06682\n",
      "Epoch: 2200, loss: 0.04302\n",
      "Epoch: 2300, loss: 0.02767\n",
      "Epoch: 2400, loss: 0.01960\n",
      "Epoch: 2500, loss: 0.01230\n",
      "Epoch: 2600, loss: 0.00918\n",
      "Epoch: 2700, loss: 0.00912\n",
      "Epoch: 2800, loss: 0.00234\n",
      "Epoch: 2900, loss: 0.00129\n",
      "Epoch: 3000, loss: 0.00140\n",
      "Epoch: 3100, loss: 0.00067\n",
      "Epoch: 3200, loss: 0.00079\n",
      "Epoch: 3300, loss: 0.00045\n",
      "Epoch: 3400, loss: 0.00059\n",
      "Epoch: 3500, loss: 0.00046\n",
      "Epoch: 3600, loss: 0.00053\n",
      "Epoch: 3700, loss: 0.00048\n",
      "Epoch: 3800, loss: 0.18258\n",
      "Epoch: 3900, loss: 0.01985\n",
      "Epoch: 4000, loss: 0.00744\n",
      "Epoch: 4100, loss: 0.00425\n",
      "Epoch: 4200, loss: 0.00226\n",
      "Epoch: 4300, loss: 0.00209\n",
      "Epoch: 4400, loss: 0.02896\n",
      "Epoch: 4500, loss: 0.00405\n",
      "Epoch: 4600, loss: 0.00183\n",
      "Epoch: 4700, loss: 0.00167\n",
      "Epoch: 4800, loss: 0.00169\n",
      "Epoch: 4900, loss: 0.00084\n",
      "Epoch: 5000, loss: 0.00082\n",
      "Epoch: 5100, loss: 0.00064\n",
      "Epoch: 5200, loss: 0.00049\n",
      "Epoch: 5300, loss: 0.00029\n",
      "Epoch: 5400, loss: 0.00037\n",
      "Epoch: 5500, loss: 0.00014\n",
      "Epoch: 5600, loss: 0.00028\n",
      "Epoch: 5700, loss: 0.00011\n",
      "Epoch: 5800, loss: 0.00028\n",
      "Epoch: 5900, loss: 0.00010\n",
      "Epoch: 6000, loss: 0.00012\n",
      "Epoch: 6100, loss: 0.00021\n",
      "Epoch: 6200, loss: 0.00016\n",
      "Epoch: 6300, loss: 0.00012\n",
      "Epoch: 6400, loss: 0.00011\n",
      "Epoch: 6500, loss: 0.00059\n",
      "Epoch: 6600, loss: 0.08164\n",
      "Epoch: 6700, loss: 0.01212\n",
      "Epoch: 6800, loss: 0.00708\n",
      "Epoch: 6900, loss: 0.00232\n",
      "Epoch: 7000, loss: 0.00135\n",
      "Epoch: 7100, loss: 0.00116\n",
      "Epoch: 7200, loss: 0.00083\n",
      "Epoch: 7300, loss: 0.00073\n",
      "Epoch: 7400, loss: 0.00034\n",
      "Epoch: 7500, loss: 0.00053\n",
      "Epoch: 7600, loss: 0.00058\n",
      "Epoch: 7700, loss: 0.00036\n",
      "Epoch: 7800, loss: 0.00038\n",
      "Epoch: 7900, loss: 0.03767\n",
      "Epoch: 8000, loss: 0.00557\n",
      "Epoch: 8100, loss: 0.00224\n",
      "Epoch: 8200, loss: 0.00075\n",
      "Epoch: 8300, loss: 0.00068\n",
      "Epoch: 8400, loss: 0.00051\n",
      "Epoch: 8500, loss: 0.00048\n",
      "Epoch: 8600, loss: 0.00012\n",
      "Epoch: 8700, loss: 0.00025\n",
      "Epoch: 8800, loss: 0.00013\n",
      "Epoch: 8900, loss: 0.00013\n",
      "Epoch: 9000, loss: 0.00016\n",
      "Epoch: 9100, loss: 0.00019\n",
      "Epoch: 9200, loss: 0.00014\n",
      "Epoch: 9300, loss: 0.04556\n",
      "Epoch: 9400, loss: 0.00233\n",
      "Epoch: 9500, loss: 0.00099\n",
      "Epoch: 9600, loss: 0.00055\n",
      "Epoch: 9700, loss: 0.00059\n",
      "Epoch: 9800, loss: 0.00027\n",
      "Epoch: 9900, loss: 0.00031\n",
      "Epoch: 10000, loss: 0.00039\n",
      "Epoch: 10100, loss: 0.00018\n",
      "Epoch: 10200, loss: 0.00022\n",
      "Epoch: 10300, loss: 0.00016\n",
      "Epoch: 10400, loss: 0.00018\n",
      "Epoch: 10500, loss: 0.00014\n",
      "Epoch: 10600, loss: 0.00026\n",
      "Epoch: 10700, loss: 0.00014\n",
      "Epoch: 10800, loss: 0.00015\n",
      "Epoch: 10900, loss: 0.00016\n",
      "Epoch: 11000, loss: 0.00014\n",
      "Epoch: 11100, loss: 0.00076\n",
      "Epoch: 11200, loss: 0.00008\n",
      "Epoch: 11300, loss: 0.00008\n",
      "Epoch: 11400, loss: 0.00015\n",
      "Epoch: 11500, loss: 0.00231\n",
      "Epoch: 11600, loss: 0.00044\n",
      "Epoch: 11700, loss: 0.00027\n",
      "Epoch: 11800, loss: 0.00013\n",
      "Epoch: 11900, loss: 0.00028\n",
      "Epoch: 12000, loss: 0.00020\n",
      "Epoch: 12100, loss: 0.00012\n",
      "Epoch: 12200, loss: 0.00010\n",
      "Epoch: 12300, loss: 0.00009\n",
      "Epoch: 12400, loss: 0.00011\n",
      "Epoch: 12500, loss: 0.00012\n",
      "Epoch: 12600, loss: 0.00006\n",
      "Epoch: 12700, loss: 0.00006\n",
      "Epoch: 12800, loss: 0.00007\n",
      "Epoch: 12900, loss: 0.00010\n",
      "Epoch: 13000, loss: 0.00011\n",
      "Epoch: 13100, loss: 0.00006\n",
      "Epoch: 13200, loss: 0.00005\n",
      "Epoch: 13300, loss: 0.00004\n",
      "Epoch: 13400, loss: 0.00005\n",
      "Epoch: 13500, loss: 0.00011\n",
      "Epoch: 13600, loss: 0.00006\n",
      "Epoch: 13700, loss: 0.00006\n",
      "Epoch: 13800, loss: 0.07256\n",
      "Epoch: 13900, loss: 0.00132\n",
      "Epoch: 14000, loss: 0.00051\n",
      "Epoch: 14100, loss: 0.00022\n",
      "Epoch: 14200, loss: 0.00015\n",
      "Epoch: 14300, loss: 0.00009\n",
      "Epoch: 14400, loss: 0.00012\n",
      "Epoch: 14500, loss: 0.00010\n",
      "Epoch: 14600, loss: 0.00007\n",
      "Epoch: 14700, loss: 0.00008\n",
      "Epoch: 14800, loss: 0.00008\n",
      "Epoch: 14900, loss: 0.00006\n",
      "Epoch: 15000, loss: 0.00011\n",
      "Epoch: 15100, loss: 0.00013\n",
      "Epoch: 15200, loss: 0.00021\n",
      "Epoch: 15300, loss: 0.00006\n",
      "Epoch: 15400, loss: 0.00003\n",
      "Epoch: 15500, loss: 0.00010\n",
      "Epoch: 15600, loss: 0.00004\n",
      "Epoch: 15700, loss: 0.00193\n",
      "Epoch: 15800, loss: 0.00067\n",
      "Epoch: 15900, loss: 0.00026\n",
      "Epoch: 16000, loss: 0.00014\n",
      "Epoch: 16100, loss: 0.00018\n",
      "Epoch: 16200, loss: 0.00017\n",
      "Epoch: 16300, loss: 0.00021\n",
      "Epoch: 16400, loss: 0.00011\n",
      "Epoch: 16500, loss: 0.00010\n",
      "Epoch: 16600, loss: 0.00016\n",
      "Epoch: 16700, loss: 0.00012\n",
      "Epoch: 16800, loss: 0.00018\n",
      "Epoch: 16900, loss: 0.00008\n",
      "Epoch: 17000, loss: 0.00013\n",
      "Epoch: 17100, loss: 0.00013\n",
      "Epoch: 17200, loss: 0.00006\n",
      "Epoch: 17300, loss: 0.00003\n",
      "Epoch: 17400, loss: 0.00005\n",
      "Epoch: 17500, loss: 0.00004\n",
      "Epoch: 17600, loss: 0.00009\n",
      "Epoch: 17700, loss: 0.00006\n",
      "Epoch: 17800, loss: 0.00003\n",
      "Epoch: 17900, loss: 0.00077\n",
      "Epoch: 18000, loss: 0.00094\n",
      "Epoch: 18100, loss: 0.00018\n",
      "Epoch: 18200, loss: 0.00009\n",
      "Epoch: 18300, loss: 0.00007\n",
      "Epoch: 18400, loss: 0.00005\n",
      "Epoch: 18500, loss: 0.00004\n",
      "Epoch: 18600, loss: 0.00004\n",
      "Epoch: 18700, loss: 0.00006\n",
      "Epoch: 18800, loss: 0.00006\n",
      "Epoch: 18900, loss: 0.00002\n",
      "Epoch: 19000, loss: 0.00002\n",
      "Epoch: 19100, loss: 0.00004\n",
      "Epoch: 19200, loss: 0.00002\n",
      "Epoch: 19300, loss: 0.00007\n",
      "Epoch: 19400, loss: 0.00001\n",
      "Epoch: 19500, loss: 0.00003\n",
      "Epoch: 19600, loss: 0.00004\n",
      "Epoch: 19700, loss: 0.00003\n",
      "Epoch: 19800, loss: 0.00001\n",
      "Epoch: 19900, loss: 0.00002\n",
      "Epoch: 20000, loss: 0.00041\n",
      "Epoch: 20100, loss: 0.00025\n",
      "Epoch: 20200, loss: 0.00005\n",
      "Epoch: 20300, loss: 0.00007\n",
      "Epoch: 20400, loss: 0.00005\n",
      "Epoch: 20500, loss: 0.00003\n",
      "Epoch: 20600, loss: 0.00005\n",
      "Epoch: 20700, loss: 0.00006\n",
      "Epoch: 20800, loss: 0.00003\n",
      "Epoch: 20900, loss: 0.00002\n",
      "Epoch: 21000, loss: 0.00004\n",
      "Epoch: 21100, loss: 0.00002\n",
      "Epoch: 21200, loss: 0.00002\n",
      "Epoch: 21300, loss: 0.00002\n",
      "Epoch: 21400, loss: 0.00003\n",
      "Epoch: 21500, loss: 0.00001\n",
      "Epoch: 21600, loss: 0.00002\n",
      "Epoch: 21700, loss: 0.00002\n",
      "Epoch: 21800, loss: 0.00004\n",
      "Epoch: 21900, loss: 0.00002\n",
      "Epoch: 22000, loss: 0.00003\n",
      "Epoch: 22100, loss: 0.00003\n",
      "Epoch: 22200, loss: 0.00002\n",
      "Epoch: 22300, loss: 0.00278\n",
      "Epoch: 22400, loss: 0.00025\n",
      "Epoch: 22500, loss: 0.00013\n",
      "Epoch: 22600, loss: 0.00009\n",
      "Epoch: 22700, loss: 0.00009\n",
      "Epoch: 22800, loss: 0.00003\n",
      "Epoch: 22900, loss: 0.00004\n",
      "Epoch: 23000, loss: 0.00002\n",
      "Epoch: 23100, loss: 0.00002\n",
      "Epoch: 23200, loss: 0.00003\n",
      "Epoch: 23300, loss: 0.00003\n",
      "Epoch: 23400, loss: 0.00006\n",
      "Epoch: 23500, loss: 0.00002\n",
      "Epoch: 23600, loss: 0.00001\n",
      "Epoch: 23700, loss: 0.00009\n",
      "Epoch: 23800, loss: 0.00003\n",
      "Epoch: 23900, loss: 0.00003\n",
      "Epoch: 24000, loss: 0.00003\n",
      "Epoch: 24100, loss: 0.00035\n",
      "Epoch: 24200, loss: 0.00017\n",
      "Epoch: 24300, loss: 0.00010\n",
      "Epoch: 24400, loss: 0.00004\n",
      "Epoch: 24500, loss: 0.00004\n",
      "Epoch: 24600, loss: 0.00003\n",
      "Epoch: 24700, loss: 0.00003\n",
      "Epoch: 24800, loss: 0.00002\n",
      "Epoch: 24900, loss: 0.00003\n",
      "Epoch: 25000, loss: 0.00003\n",
      "Epoch: 25100, loss: 0.00012\n",
      "Epoch: 25200, loss: 0.00002\n",
      "Epoch: 25300, loss: 0.00002\n",
      "Epoch: 25400, loss: 0.00101\n",
      "Epoch: 25500, loss: 0.00007\n",
      "Epoch: 25600, loss: 0.00004\n",
      "Epoch: 25700, loss: 0.00003\n",
      "Epoch: 25800, loss: 0.00002\n",
      "Epoch: 25900, loss: 0.00003\n",
      "Epoch: 26000, loss: 0.00001\n",
      "Epoch: 26100, loss: 0.00003\n",
      "Epoch: 26200, loss: 0.00001\n",
      "Epoch: 26300, loss: 0.00003\n",
      "Epoch: 26400, loss: 0.00001\n",
      "Epoch: 26500, loss: 0.00002\n",
      "Epoch: 26600, loss: 0.00002\n",
      "Epoch: 26700, loss: 0.00001\n",
      "Epoch: 26800, loss: 0.00001\n",
      "Epoch: 26900, loss: 0.00003\n",
      "Epoch: 27000, loss: 0.00001\n",
      "Epoch: 27100, loss: 0.00001\n",
      "Epoch: 27200, loss: 0.00002\n",
      "Epoch: 27300, loss: 0.00001\n",
      "Epoch: 27400, loss: 0.00002\n",
      "Epoch: 27500, loss: 0.00003\n",
      "Epoch: 27600, loss: 0.00248\n",
      "Epoch: 27700, loss: 0.00005\n",
      "Epoch: 27800, loss: 0.00007\n",
      "Epoch: 27900, loss: 0.00003\n",
      "Epoch: 28000, loss: 0.00002\n",
      "Epoch: 28100, loss: 0.00001\n",
      "Epoch: 28200, loss: 0.00001\n",
      "Epoch: 28300, loss: 0.00001\n",
      "Epoch: 28400, loss: 0.00001\n",
      "Epoch: 28500, loss: 0.00002\n",
      "Epoch: 28600, loss: 0.00001\n",
      "Epoch: 28700, loss: 0.00001\n",
      "Epoch: 28800, loss: 0.00002\n",
      "Epoch: 28900, loss: 0.00001\n",
      "Epoch: 29000, loss: 0.00001\n",
      "Epoch: 29100, loss: 0.00001\n",
      "Epoch: 29200, loss: 0.00002\n",
      "Epoch: 29300, loss: 0.00001\n",
      "Epoch: 29400, loss: 0.00004\n",
      "Epoch: 29500, loss: 0.00001\n",
      "Epoch: 29600, loss: 0.00001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29700, loss: 0.00001\n",
      "Epoch: 29800, loss: 0.00001\n",
      "Epoch: 29900, loss: 0.00001\n",
      "Epoch: 30000, loss: 0.00001\n",
      "Epoch: 30100, loss: 0.00001\n",
      "Epoch: 30200, loss: 0.00001\n",
      "Epoch: 30300, loss: 0.00051\n",
      "Epoch: 30400, loss: 0.00011\n",
      "Epoch: 30500, loss: 0.00002\n",
      "Epoch: 30600, loss: 0.00001\n",
      "Epoch: 30700, loss: 0.00001\n",
      "Epoch: 30800, loss: 0.00001\n",
      "Epoch: 30900, loss: 0.00001\n",
      "Epoch: 31000, loss: 0.00001\n",
      "Epoch: 31100, loss: 0.00001\n",
      "Epoch: 31200, loss: 0.00001\n",
      "Epoch: 31300, loss: 0.00001\n",
      "Epoch: 31400, loss: 0.00001\n",
      "Epoch: 31500, loss: 0.00001\n",
      "Epoch: 31600, loss: 0.00001\n",
      "Epoch: 31700, loss: 0.00001\n",
      "Epoch: 31800, loss: 0.00002\n",
      "Epoch: 31900, loss: 0.00001\n",
      "Epoch: 32000, loss: 0.00004\n",
      "Epoch: 32100, loss: 0.00001\n",
      "Epoch: 32200, loss: 0.00001\n",
      "Epoch: 32300, loss: 0.00001\n",
      "Epoch: 32400, loss: 0.00001\n",
      "Epoch: 32500, loss: 0.00001\n",
      "Epoch: 32600, loss: 0.00001\n",
      "Epoch: 32700, loss: 0.00493\n",
      "Epoch: 32800, loss: 0.00006\n",
      "Epoch: 32900, loss: 0.00002\n",
      "Epoch: 33000, loss: 0.00003\n",
      "Epoch: 33100, loss: 0.00002\n",
      "Epoch: 33200, loss: 0.00001\n",
      "Epoch: 33300, loss: 0.00001\n",
      "Epoch: 33400, loss: 0.00007\n",
      "Epoch: 33500, loss: 0.00001\n",
      "Epoch: 33600, loss: 0.00001\n",
      "Epoch: 33700, loss: 0.00002\n",
      "Epoch: 33800, loss: 0.00001\n",
      "Epoch: 33900, loss: 0.00001\n",
      "Epoch: 34000, loss: 0.00001\n",
      "Epoch: 34100, loss: 0.00001\n",
      "Epoch: 34200, loss: 0.00003\n",
      "Epoch: 34300, loss: 0.00001\n",
      "Epoch: 34400, loss: 0.00001\n",
      "Epoch: 34500, loss: 0.00001\n",
      "Epoch: 34600, loss: 0.00001\n",
      "Epoch: 34700, loss: 0.00001\n",
      "Epoch: 34800, loss: 0.00001\n",
      "Epoch: 34900, loss: 0.00001\n",
      "Epoch: 35000, loss: 0.00001\n",
      "Epoch: 35100, loss: 0.00001\n",
      "Epoch: 35200, loss: 0.00001\n",
      "Epoch: 35300, loss: 0.00001\n",
      "Epoch: 35400, loss: 0.00001\n",
      "Epoch: 35500, loss: 0.00001\n",
      "Epoch: 35600, loss: 0.00001\n",
      "Epoch: 35700, loss: 0.00002\n",
      "Epoch: 35800, loss: 0.00001\n",
      "Epoch: 35900, loss: 0.00001\n",
      "Epoch: 36000, loss: 0.00001\n",
      "Epoch: 36100, loss: 0.00002\n",
      "Epoch: 36200, loss: 0.00001\n",
      "Epoch: 36300, loss: 0.00001\n",
      "Epoch: 36400, loss: 0.00681\n",
      "Epoch: 36500, loss: 0.00012\n",
      "Epoch: 36600, loss: 0.00011\n",
      "Epoch: 36700, loss: 0.00003\n",
      "Epoch: 36800, loss: 0.00004\n",
      "Epoch: 36900, loss: 0.00003\n",
      "Epoch: 37000, loss: 0.00003\n",
      "Epoch: 37100, loss: 0.00002\n",
      "Epoch: 37200, loss: 0.00004\n",
      "Epoch: 37300, loss: 0.00001\n",
      "Epoch: 37400, loss: 0.00002\n",
      "Epoch: 37500, loss: 0.00001\n",
      "Epoch: 37600, loss: 0.00002\n",
      "Epoch: 37700, loss: 0.00001\n",
      "Epoch: 37800, loss: 0.00002\n",
      "Epoch: 37900, loss: 0.00002\n",
      "Epoch: 38000, loss: 0.00001\n",
      "Epoch: 38100, loss: 0.00002\n",
      "Epoch: 38200, loss: 0.00001\n",
      "Epoch: 38300, loss: 0.00001\n",
      "Epoch: 38400, loss: 0.00007\n",
      "Epoch: 38500, loss: 0.00007\n",
      "Epoch: 38600, loss: 0.00007\n",
      "Epoch: 38700, loss: 0.00003\n",
      "Epoch: 38800, loss: 0.00003\n",
      "Epoch: 38900, loss: 0.00002\n",
      "Epoch: 39000, loss: 0.00001\n",
      "Epoch: 39100, loss: 0.00001\n",
      "Epoch: 39200, loss: 0.00001\n",
      "Epoch: 39300, loss: 0.00002\n",
      "Epoch: 39400, loss: 0.00001\n",
      "Epoch: 39500, loss: 0.00001\n",
      "Epoch: 39600, loss: 0.00004\n",
      "Epoch: 39700, loss: 0.00001\n",
      "Epoch: 39800, loss: 0.00001\n",
      "Epoch: 39900, loss: 0.00001\n",
      "Epoch: 40000, loss: 0.00001\n",
      "Epoch: 40100, loss: 0.00001\n",
      "Epoch: 40200, loss: 0.00001\n",
      "Epoch: 40300, loss: 0.00001\n",
      "Epoch: 40400, loss: 0.00001\n",
      "Epoch: 40500, loss: 0.00002\n",
      "Epoch: 40600, loss: 0.00001\n",
      "Epoch: 40700, loss: 0.00001\n",
      "Epoch: 40800, loss: 0.00003\n",
      "Epoch: 40900, loss: 0.00001\n",
      "Epoch: 41000, loss: 0.00115\n",
      "Epoch: 41100, loss: 0.00128\n",
      "Epoch: 41200, loss: 0.00007\n",
      "Epoch: 41300, loss: 0.00007\n",
      "Epoch: 41400, loss: 0.00003\n",
      "Epoch: 41500, loss: 0.00002\n",
      "Epoch: 41600, loss: 0.00003\n",
      "Epoch: 41700, loss: 0.00004\n",
      "Epoch: 41800, loss: 0.00002\n",
      "Epoch: 41900, loss: 0.00003\n",
      "Epoch: 42000, loss: 0.00002\n",
      "Epoch: 42100, loss: 0.00002\n",
      "Epoch: 42200, loss: 0.00003\n",
      "Epoch: 42300, loss: 0.00002\n",
      "Epoch: 42400, loss: 0.00001\n",
      "Epoch: 42500, loss: 0.00002\n",
      "Epoch: 42600, loss: 0.00001\n",
      "Epoch: 42700, loss: 0.00001\n",
      "Epoch: 42800, loss: 0.00003\n",
      "Epoch: 42900, loss: 0.00068\n",
      "Epoch: 43000, loss: 0.00020\n",
      "Epoch: 43100, loss: 0.00013\n",
      "Epoch: 43200, loss: 0.00007\n",
      "Epoch: 43300, loss: 0.00005\n",
      "Epoch: 43400, loss: 0.00004\n",
      "Epoch: 43500, loss: 0.00007\n",
      "Epoch: 43600, loss: 0.00007\n",
      "Epoch: 43700, loss: 0.00007\n",
      "Epoch: 43800, loss: 0.00005\n",
      "Epoch: 43900, loss: 0.00006\n",
      "Epoch: 44000, loss: 0.00007\n",
      "Epoch: 44100, loss: 0.00007\n",
      "Epoch: 44200, loss: 0.00004\n",
      "Epoch: 44300, loss: 0.00004\n",
      "Epoch: 44400, loss: 0.00001\n",
      "Epoch: 44500, loss: 0.00002\n",
      "Epoch: 44600, loss: 0.00004\n",
      "Epoch: 44700, loss: 0.00003\n",
      "Epoch: 44800, loss: 0.00006\n",
      "Epoch: 44900, loss: 0.00039\n",
      "Epoch: 45000, loss: 0.00009\n",
      "Epoch: 45100, loss: 0.00005\n",
      "Epoch: 45200, loss: 0.00011\n",
      "Epoch: 45300, loss: 0.00003\n",
      "Epoch: 45400, loss: 0.00001\n",
      "Epoch: 45500, loss: 0.00003\n",
      "Epoch: 45600, loss: 0.00002\n",
      "Epoch: 45700, loss: 0.00001\n",
      "Epoch: 45800, loss: 0.00002\n",
      "Epoch: 45900, loss: 0.00002\n",
      "Epoch: 46000, loss: 0.00001\n",
      "Epoch: 46100, loss: 0.00005\n",
      "Epoch: 46200, loss: 0.00004\n",
      "Epoch: 46300, loss: 0.00005\n",
      "Epoch: 46400, loss: 0.00001\n",
      "Epoch: 46500, loss: 0.00001\n",
      "Epoch: 46600, loss: 0.00002\n",
      "Epoch: 46700, loss: 0.00002\n",
      "Epoch: 46800, loss: 0.00005\n",
      "Epoch: 46900, loss: 0.00005\n",
      "Epoch: 47000, loss: 0.00002\n",
      "Epoch: 47100, loss: 0.00001\n",
      "Epoch: 47200, loss: 0.00001\n",
      "Epoch: 47300, loss: 0.00002\n",
      "Epoch: 47400, loss: 0.00001\n",
      "Epoch: 47500, loss: 0.00001\n",
      "Epoch: 47600, loss: 0.00002\n",
      "Epoch: 47700, loss: 0.00002\n",
      "Epoch: 47800, loss: 0.00001\n",
      "Epoch: 47900, loss: 0.00001\n",
      "Epoch: 48000, loss: 0.00001\n",
      "Epoch: 48100, loss: 0.00001\n",
      "Epoch: 48200, loss: 0.00001\n",
      "Epoch: 48300, loss: 0.00002\n",
      "Epoch: 48400, loss: 0.00001\n",
      "Epoch: 48500, loss: 0.00001\n",
      "Epoch: 48600, loss: 0.00036\n",
      "Epoch: 48700, loss: 0.00005\n",
      "Epoch: 48800, loss: 0.00005\n",
      "Epoch: 48900, loss: 0.00003\n",
      "Epoch: 49000, loss: 0.00002\n",
      "Epoch: 49100, loss: 0.00004\n",
      "Epoch: 49200, loss: 0.00002\n",
      "Epoch: 49300, loss: 0.00003\n",
      "Epoch: 49400, loss: 0.00005\n",
      "Epoch: 49500, loss: 0.00001\n",
      "Epoch: 49600, loss: 0.00002\n",
      "Epoch: 49700, loss: 0.00002\n",
      "Epoch: 49800, loss: 0.00001\n",
      "Epoch: 49900, loss: 0.00001\n",
      "Epoch: 50000, loss: 0.00002\n",
      "Epoch: 50100, loss: 0.00001\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = model(train_data_x)\n",
    "    loss = criterion(outputs, train_data_y.squeeze())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))\n",
    "    \"\"\"for batch_X, batch_Y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_Y.squeeze())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d32a7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the network multiple times with dropout turned on\n",
    "#model.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02f4dc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = joblib.load('sc.joblib')\n",
    "#transformedData = sc.transform(test_x)\n",
    "transformedData = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f618a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_y=Y_train[-128:].values.reshape(-1, 1)\n",
    "transformedData_y=test_y.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39db417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model for predictions\n",
    "test_data = MyDataset(transformedData, transformedData_y)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f112b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(10, 90, num_layers=5, batch_first=True)\n",
       "  (fc): Linear(in_features=90, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89a3041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_x=test_data.X.to(device)\n",
    "\n",
    "#====================\n",
    "#testing purposes only\n",
    "#test_data_x=train_data.X[-21:].to(device)\n",
    "#test_data.Y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c1d371c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(10, 90, num_layers=5, batch_first=True)\n",
       "  (fc): Linear(in_features=90, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputlist=[]\n",
    "model.train()\n",
    "len_outputs=100\n",
    "with torch.no_grad():\n",
    "    for i in range(len_outputs):\n",
    "        output = model(test_data_x)\n",
    "        outputlist.append(output)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bdae692d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_output_list=[]\n",
    "for outputs in outputlist:\n",
    "    scaled_output=outputs.cpu().reshape(-1, 1)\n",
    "    scaled_output_list.append(scaled_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14cbf7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_list_to_dataframe(arrays,length):\n",
    "    # Convert the list of arrays to a single 2D array\n",
    "    array_2d = np.concatenate(arrays, axis=1)\n",
    "    \n",
    "    # Reshape the 2D array into a 5-column array\n",
    "    array_5col = np.reshape(array_2d, (-1, length))\n",
    "    \n",
    "    # Create a DataFrame from the 5-column array\n",
    "    df = pd.DataFrame(array_5col)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "646b712f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4      5      6      7      8      9   ...  \\\n",
       "0   False  False  False  False  False  False  False  False  False  False  ...   \n",
       "1   False  False  False  False  False  False  False  False  False  False  ...   \n",
       "2   False  False  False  False  False  False  False  False  False  False  ...   \n",
       "3   False  False  False  False  False  False  False  False  False  False  ...   \n",
       "4   False  False  False  False  False  False  False  False  False  False  ...   \n",
       "5   False  False  False  False  False  False  False  False  False  False  ...   \n",
       "6   False  False  False  False  False  False  False  False  False  False  ...   \n",
       "7   False  False  False  False  False  False  False  False  False  False  ...   \n",
       "8   False  False  False  False  False  False  False  False  False  False  ...   \n",
       "9   False  False  False  False  False  False  False  False  False  False  ...   \n",
       "10  False  False  False  False  False  False  False  False  False  False  ...   \n",
       "11  False  False  False  False  False  False  False  False  False  False  ...   \n",
       "\n",
       "       90     91     92     93     94     95     96     97     98     99  \n",
       "0   False  False  False  False  False  False  False  False  False  False  \n",
       "1   False  False  False  False  False  False  False  False  False  False  \n",
       "2   False  False  False  False  False  False  False  False  False  False  \n",
       "3   False  False  False  False  False  False  False  False  False  False  \n",
       "4   False  False  False  False  False  False  False  False  False  False  \n",
       "5   False  False  False  False  False  False  False  False  False  False  \n",
       "6   False  False  False  False  False  False  False  False  False  False  \n",
       "7   False  False  False  False  False  False  False  False  False  False  \n",
       "8   False  False  False  False  False  False  False  False  False  False  \n",
       "9   False  False  False  False  False  False  False  False  False  False  \n",
       "10  False  False  False  False  False  False  False  False  False  False  \n",
       "11  False  False  False  False  False  False  False  False  False  False  \n",
       "\n",
       "[12 rows x 100 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_list_to_dataframe(scaled_output_list,len_outputs )> .9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9d58fb18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test=array_list_to_dataframe(scaled_output_list,len_outputs )\n",
    "testarray=test.iloc[:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98de64bf",
   "metadata": {},
   "source": [
    "# Sigmoid Label Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ffeb8c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count1 = (testarray > .99).sum(axis=1)\n",
    "count2=(testarray > .999).sum(axis=1)\n",
    "count3=(testarray > .9999).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "462068b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     4\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d827e354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.677959e-04</td>\n",
       "      <td>1.869752e-07</td>\n",
       "      <td>1.324246e-05</td>\n",
       "      <td>5.404076e-05</td>\n",
       "      <td>4.187386e-05</td>\n",
       "      <td>2.107408e-03</td>\n",
       "      <td>4.521722e-07</td>\n",
       "      <td>9.557757e-07</td>\n",
       "      <td>2.716579e-05</td>\n",
       "      <td>2.368615e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>5.070763e-05</td>\n",
       "      <td>1.494888e-05</td>\n",
       "      <td>4.365377e-06</td>\n",
       "      <td>1.664984e-06</td>\n",
       "      <td>5.033584e-06</td>\n",
       "      <td>5.017869e-07</td>\n",
       "      <td>8.589566e-05</td>\n",
       "      <td>1.646490e-06</td>\n",
       "      <td>2.209916e-05</td>\n",
       "      <td>5.278027e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.864561e-08</td>\n",
       "      <td>7.567501e-11</td>\n",
       "      <td>5.358310e-10</td>\n",
       "      <td>1.019591e-07</td>\n",
       "      <td>2.116911e-08</td>\n",
       "      <td>8.415214e-11</td>\n",
       "      <td>2.130656e-11</td>\n",
       "      <td>1.668469e-07</td>\n",
       "      <td>3.446665e-09</td>\n",
       "      <td>5.527184e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>9.612493e-11</td>\n",
       "      <td>1.823665e-09</td>\n",
       "      <td>1.298457e-07</td>\n",
       "      <td>1.299509e-13</td>\n",
       "      <td>1.978204e-09</td>\n",
       "      <td>1.428204e-10</td>\n",
       "      <td>3.173640e-10</td>\n",
       "      <td>3.577991e-11</td>\n",
       "      <td>7.667950e-13</td>\n",
       "      <td>1.774638e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.744739e-02</td>\n",
       "      <td>3.128206e-04</td>\n",
       "      <td>6.454992e-03</td>\n",
       "      <td>8.355989e-02</td>\n",
       "      <td>7.640725e-03</td>\n",
       "      <td>3.376525e-04</td>\n",
       "      <td>2.231725e-03</td>\n",
       "      <td>1.062144e-02</td>\n",
       "      <td>1.329030e-03</td>\n",
       "      <td>4.027835e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.003459e-01</td>\n",
       "      <td>6.768250e-03</td>\n",
       "      <td>8.658184e-05</td>\n",
       "      <td>5.096021e-03</td>\n",
       "      <td>8.325430e-04</td>\n",
       "      <td>1.518515e-04</td>\n",
       "      <td>7.795495e-04</td>\n",
       "      <td>6.969220e-04</td>\n",
       "      <td>1.159364e-02</td>\n",
       "      <td>3.167674e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.983695e-05</td>\n",
       "      <td>6.833614e-05</td>\n",
       "      <td>3.431430e-06</td>\n",
       "      <td>1.225967e-03</td>\n",
       "      <td>2.810460e-06</td>\n",
       "      <td>3.292839e-04</td>\n",
       "      <td>3.224208e-04</td>\n",
       "      <td>5.457075e-06</td>\n",
       "      <td>6.393307e-05</td>\n",
       "      <td>1.313614e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>5.033896e-06</td>\n",
       "      <td>7.016864e-05</td>\n",
       "      <td>8.195769e-05</td>\n",
       "      <td>2.871876e-04</td>\n",
       "      <td>1.582606e-03</td>\n",
       "      <td>6.112871e-06</td>\n",
       "      <td>1.748495e-03</td>\n",
       "      <td>6.863639e-06</td>\n",
       "      <td>6.345444e-05</td>\n",
       "      <td>3.660891e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.298653e-11</td>\n",
       "      <td>1.934863e-10</td>\n",
       "      <td>3.413874e-08</td>\n",
       "      <td>8.658160e-12</td>\n",
       "      <td>1.357800e-07</td>\n",
       "      <td>5.578721e-08</td>\n",
       "      <td>3.044452e-12</td>\n",
       "      <td>4.873286e-12</td>\n",
       "      <td>1.365987e-09</td>\n",
       "      <td>7.387678e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>1.099348e-10</td>\n",
       "      <td>4.669273e-09</td>\n",
       "      <td>8.439948e-08</td>\n",
       "      <td>2.736210e-13</td>\n",
       "      <td>8.839605e-13</td>\n",
       "      <td>2.880191e-09</td>\n",
       "      <td>5.893885e-13</td>\n",
       "      <td>7.661763e-10</td>\n",
       "      <td>2.939382e-11</td>\n",
       "      <td>1.386001e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.013646e-02</td>\n",
       "      <td>8.996826e-02</td>\n",
       "      <td>6.359720e-01</td>\n",
       "      <td>5.163308e-01</td>\n",
       "      <td>6.859729e-01</td>\n",
       "      <td>5.761038e-01</td>\n",
       "      <td>2.951187e-01</td>\n",
       "      <td>7.719985e-01</td>\n",
       "      <td>4.919725e-01</td>\n",
       "      <td>3.711081e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.790920e-01</td>\n",
       "      <td>7.865450e-01</td>\n",
       "      <td>6.082415e-01</td>\n",
       "      <td>9.563299e-01</td>\n",
       "      <td>7.545440e-01</td>\n",
       "      <td>1.544015e-01</td>\n",
       "      <td>4.007889e-01</td>\n",
       "      <td>8.791486e-01</td>\n",
       "      <td>9.462767e-01</td>\n",
       "      <td>5.881965e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.970293e-01</td>\n",
       "      <td>9.997557e-01</td>\n",
       "      <td>9.990820e-01</td>\n",
       "      <td>9.987380e-01</td>\n",
       "      <td>9.995341e-01</td>\n",
       "      <td>9.995458e-01</td>\n",
       "      <td>9.997081e-01</td>\n",
       "      <td>9.954786e-01</td>\n",
       "      <td>9.996848e-01</td>\n",
       "      <td>9.977561e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>9.993502e-01</td>\n",
       "      <td>9.863589e-01</td>\n",
       "      <td>9.998575e-01</td>\n",
       "      <td>9.995059e-01</td>\n",
       "      <td>9.911534e-01</td>\n",
       "      <td>9.998210e-01</td>\n",
       "      <td>9.994030e-01</td>\n",
       "      <td>9.987005e-01</td>\n",
       "      <td>9.990639e-01</td>\n",
       "      <td>9.955074e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.527294e-06</td>\n",
       "      <td>1.458096e-05</td>\n",
       "      <td>8.292510e-06</td>\n",
       "      <td>8.911487e-06</td>\n",
       "      <td>2.487943e-06</td>\n",
       "      <td>1.045544e-04</td>\n",
       "      <td>7.070566e-06</td>\n",
       "      <td>3.310117e-06</td>\n",
       "      <td>4.961858e-05</td>\n",
       "      <td>1.136552e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>4.983812e-06</td>\n",
       "      <td>7.183745e-05</td>\n",
       "      <td>1.009643e-05</td>\n",
       "      <td>3.333535e-06</td>\n",
       "      <td>1.111876e-05</td>\n",
       "      <td>3.282698e-06</td>\n",
       "      <td>4.109027e-05</td>\n",
       "      <td>1.336039e-05</td>\n",
       "      <td>5.356836e-03</td>\n",
       "      <td>1.237875e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.634983e-04</td>\n",
       "      <td>2.243139e-05</td>\n",
       "      <td>2.546468e-03</td>\n",
       "      <td>1.010035e-03</td>\n",
       "      <td>4.846599e-04</td>\n",
       "      <td>2.451232e-05</td>\n",
       "      <td>1.366769e-03</td>\n",
       "      <td>2.381715e-04</td>\n",
       "      <td>8.968060e-04</td>\n",
       "      <td>7.068974e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.157140e-05</td>\n",
       "      <td>2.080366e-02</td>\n",
       "      <td>7.041308e-02</td>\n",
       "      <td>3.954768e-04</td>\n",
       "      <td>1.004166e-02</td>\n",
       "      <td>1.147873e-03</td>\n",
       "      <td>2.722435e-03</td>\n",
       "      <td>1.103688e-02</td>\n",
       "      <td>9.603875e-05</td>\n",
       "      <td>2.361841e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.026591e-10</td>\n",
       "      <td>1.424863e-09</td>\n",
       "      <td>6.754451e-08</td>\n",
       "      <td>1.467963e-07</td>\n",
       "      <td>1.611446e-07</td>\n",
       "      <td>4.240135e-08</td>\n",
       "      <td>1.866329e-08</td>\n",
       "      <td>3.012423e-08</td>\n",
       "      <td>8.379122e-09</td>\n",
       "      <td>2.533608e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>6.438805e-06</td>\n",
       "      <td>1.681611e-06</td>\n",
       "      <td>6.317435e-11</td>\n",
       "      <td>1.801661e-06</td>\n",
       "      <td>6.062972e-08</td>\n",
       "      <td>8.498639e-11</td>\n",
       "      <td>7.864494e-09</td>\n",
       "      <td>7.213227e-07</td>\n",
       "      <td>2.550978e-06</td>\n",
       "      <td>1.103231e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.031176e-09</td>\n",
       "      <td>6.051779e-11</td>\n",
       "      <td>2.556853e-09</td>\n",
       "      <td>6.472664e-08</td>\n",
       "      <td>4.606551e-11</td>\n",
       "      <td>2.971065e-08</td>\n",
       "      <td>2.840529e-09</td>\n",
       "      <td>3.682871e-07</td>\n",
       "      <td>2.282705e-11</td>\n",
       "      <td>1.437282e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>7.036758e-10</td>\n",
       "      <td>3.410578e-10</td>\n",
       "      <td>4.400301e-07</td>\n",
       "      <td>8.081368e-08</td>\n",
       "      <td>1.768291e-10</td>\n",
       "      <td>8.550608e-10</td>\n",
       "      <td>2.953649e-09</td>\n",
       "      <td>3.231402e-08</td>\n",
       "      <td>1.063743e-09</td>\n",
       "      <td>3.515661e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.156163e-06</td>\n",
       "      <td>2.065545e-10</td>\n",
       "      <td>1.066812e-07</td>\n",
       "      <td>3.354453e-08</td>\n",
       "      <td>5.869534e-08</td>\n",
       "      <td>1.271770e-04</td>\n",
       "      <td>1.635300e-05</td>\n",
       "      <td>1.461340e-07</td>\n",
       "      <td>6.312560e-07</td>\n",
       "      <td>1.235004e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>1.256681e-06</td>\n",
       "      <td>1.818831e-08</td>\n",
       "      <td>2.485945e-07</td>\n",
       "      <td>2.994891e-09</td>\n",
       "      <td>4.155000e-08</td>\n",
       "      <td>9.434893e-08</td>\n",
       "      <td>2.512168e-08</td>\n",
       "      <td>1.119417e-07</td>\n",
       "      <td>3.372506e-08</td>\n",
       "      <td>5.845599e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0             1             2             3             4   \\\n",
       "0   2.677959e-04  1.869752e-07  1.324246e-05  5.404076e-05  4.187386e-05   \n",
       "1   6.864561e-08  7.567501e-11  5.358310e-10  1.019591e-07  2.116911e-08   \n",
       "2   3.744739e-02  3.128206e-04  6.454992e-03  8.355989e-02  7.640725e-03   \n",
       "3   5.983695e-05  6.833614e-05  3.431430e-06  1.225967e-03  2.810460e-06   \n",
       "4   2.298653e-11  1.934863e-10  3.413874e-08  8.658160e-12  1.357800e-07   \n",
       "5   2.013646e-02  8.996826e-02  6.359720e-01  5.163308e-01  6.859729e-01   \n",
       "6   9.970293e-01  9.997557e-01  9.990820e-01  9.987380e-01  9.995341e-01   \n",
       "7   9.527294e-06  1.458096e-05  8.292510e-06  8.911487e-06  2.487943e-06   \n",
       "8   3.634983e-04  2.243139e-05  2.546468e-03  1.010035e-03  4.846599e-04   \n",
       "9   4.026591e-10  1.424863e-09  6.754451e-08  1.467963e-07  1.611446e-07   \n",
       "10  1.031176e-09  6.051779e-11  2.556853e-09  6.472664e-08  4.606551e-11   \n",
       "11  4.156163e-06  2.065545e-10  1.066812e-07  3.354453e-08  5.869534e-08   \n",
       "\n",
       "              5             6             7             8             9   ...  \\\n",
       "0   2.107408e-03  4.521722e-07  9.557757e-07  2.716579e-05  2.368615e-03  ...   \n",
       "1   8.415214e-11  2.130656e-11  1.668469e-07  3.446665e-09  5.527184e-08  ...   \n",
       "2   3.376525e-04  2.231725e-03  1.062144e-02  1.329030e-03  4.027835e-02  ...   \n",
       "3   3.292839e-04  3.224208e-04  5.457075e-06  6.393307e-05  1.313614e-05  ...   \n",
       "4   5.578721e-08  3.044452e-12  4.873286e-12  1.365987e-09  7.387678e-14  ...   \n",
       "5   5.761038e-01  2.951187e-01  7.719985e-01  4.919725e-01  3.711081e-01  ...   \n",
       "6   9.995458e-01  9.997081e-01  9.954786e-01  9.996848e-01  9.977561e-01  ...   \n",
       "7   1.045544e-04  7.070566e-06  3.310117e-06  4.961858e-05  1.136552e-06  ...   \n",
       "8   2.451232e-05  1.366769e-03  2.381715e-04  8.968060e-04  7.068974e-05  ...   \n",
       "9   4.240135e-08  1.866329e-08  3.012423e-08  8.379122e-09  2.533608e-10  ...   \n",
       "10  2.971065e-08  2.840529e-09  3.682871e-07  2.282705e-11  1.437282e-09  ...   \n",
       "11  1.271770e-04  1.635300e-05  1.461340e-07  6.312560e-07  1.235004e-09  ...   \n",
       "\n",
       "              90            91            92            93            94  \\\n",
       "0   5.070763e-05  1.494888e-05  4.365377e-06  1.664984e-06  5.033584e-06   \n",
       "1   9.612493e-11  1.823665e-09  1.298457e-07  1.299509e-13  1.978204e-09   \n",
       "2   1.003459e-01  6.768250e-03  8.658184e-05  5.096021e-03  8.325430e-04   \n",
       "3   5.033896e-06  7.016864e-05  8.195769e-05  2.871876e-04  1.582606e-03   \n",
       "4   1.099348e-10  4.669273e-09  8.439948e-08  2.736210e-13  8.839605e-13   \n",
       "5   3.790920e-01  7.865450e-01  6.082415e-01  9.563299e-01  7.545440e-01   \n",
       "6   9.993502e-01  9.863589e-01  9.998575e-01  9.995059e-01  9.911534e-01   \n",
       "7   4.983812e-06  7.183745e-05  1.009643e-05  3.333535e-06  1.111876e-05   \n",
       "8   2.157140e-05  2.080366e-02  7.041308e-02  3.954768e-04  1.004166e-02   \n",
       "9   6.438805e-06  1.681611e-06  6.317435e-11  1.801661e-06  6.062972e-08   \n",
       "10  7.036758e-10  3.410578e-10  4.400301e-07  8.081368e-08  1.768291e-10   \n",
       "11  1.256681e-06  1.818831e-08  2.485945e-07  2.994891e-09  4.155000e-08   \n",
       "\n",
       "              95            96            97            98            99  \n",
       "0   5.017869e-07  8.589566e-05  1.646490e-06  2.209916e-05  5.278027e-06  \n",
       "1   1.428204e-10  3.173640e-10  3.577991e-11  7.667950e-13  1.774638e-08  \n",
       "2   1.518515e-04  7.795495e-04  6.969220e-04  1.159364e-02  3.167674e-03  \n",
       "3   6.112871e-06  1.748495e-03  6.863639e-06  6.345444e-05  3.660891e-06  \n",
       "4   2.880191e-09  5.893885e-13  7.661763e-10  2.939382e-11  1.386001e-09  \n",
       "5   1.544015e-01  4.007889e-01  8.791486e-01  9.462767e-01  5.881965e-01  \n",
       "6   9.998210e-01  9.994030e-01  9.987005e-01  9.990639e-01  9.955074e-01  \n",
       "7   3.282698e-06  4.109027e-05  1.336039e-05  5.356836e-03  1.237875e-05  \n",
       "8   1.147873e-03  2.722435e-03  1.103688e-02  9.603875e-05  2.361841e-03  \n",
       "9   8.498639e-11  7.864494e-09  7.213227e-07  2.550978e-06  1.103231e-09  \n",
       "10  8.550608e-10  2.953649e-09  3.231402e-08  1.063743e-09  3.515661e-10  \n",
       "11  9.434893e-08  2.512168e-08  1.119417e-07  3.372506e-08  5.845599e-09  \n",
       "\n",
       "[12 rows x 100 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c9c9f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38552c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13000 dropout .5\n",
    "#loss .02797"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e267d455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13000 dropout .5\n",
    "#loss: 0.02298\n",
    "#loss .0195 lowest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbcf358",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
